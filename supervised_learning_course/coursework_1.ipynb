{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent variable\n",
    "x = [1, 2, 3, 4]\n",
    "\n",
    "# Number of samples\n",
    "m = len(x)\n",
    "\n",
    "# Number of features\n",
    "n = 1\n",
    "\n",
    "# Build feature matrix\n",
    "X = np.array(x)\n",
    "X.shape = (m, n)\n",
    "\n",
    "# Observations\n",
    "y_train = np.array([3, 2, 0, 5])\n",
    "y_train.shape = (1, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title(\"Raw Data\")\n",
    "scatter(X, y_train)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_feature_map(X, k=2):\n",
    "    \"\"\"\n",
    "    Number of features, n = 1.\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    \n",
    "    phi = np.zeros(shape=(m, k))\n",
    "    \n",
    "    for i, x in enumerate(X):\n",
    "        mapped_feature = np.zeros(shape=(k))\n",
    "        for j in range(k):\n",
    "            mapped_feature[j] = x**j\n",
    "        \n",
    "        phi[i] = mapped_feature\n",
    "    \n",
    "    return np.matrix(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(Phi, y_train):\n",
    "    \"\"\"\n",
    "    Apply normal equations to find weights\n",
    "    \"\"\"\n",
    "\n",
    "    a = np.matrix(np.matmul(Phi.T, Phi))\n",
    "    b = np.matrix(np.matmul((Phi.T), y_train.T))\n",
    "\n",
    "    w = np.matmul(a.I, b)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial(x, k, *w):\n",
    "    \"\"\"\n",
    "    Apply polynomial weights derived from normal equations.\n",
    "    \"\"\"\n",
    "    result = np.zeros_like(x)\n",
    "    for i, sample in enumerate(x):\n",
    "        res = 0\n",
    "        for j in range(k):\n",
    "            res += w[j]*sample**j\n",
    "        result[i] = res\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot raw data points\n",
    "scatter(X, y_train)\n",
    "\n",
    "# Test data\n",
    "x_test = np.arange(0, 4.1, 0.1)\n",
    "\n",
    "# Plot each model\n",
    "for i in range(1, 5):\n",
    "    Phi = polynomial_feature_map(X, k=i)\n",
    "    w = linear_regression(Phi, y_train)\n",
    "    plot(x_test, polynomial(x_test, len(w), *w), label=i)\n",
    "    \n",
    "title('Linear Regression With Different Feature Maps')\n",
    "legend(title='$k$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights for k=1 to k=3\n",
    "\n",
    "for k in range(1, 4):\n",
    "    Phi = polynomial_feature_map(X, k)\n",
    "    w = linear_regression(Phi, y_train)\n",
    "    print(f\"k={k}\")\n",
    "    print(\"**********\")\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse(y, y_hat):        \n",
    "    return sum((y-y_hat)**2)\n",
    "\n",
    "def mse(y, y_hat):\n",
    "    return sse(y, y_hat)/len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_vec = []\n",
    "\n",
    "for i in range(1, 5):\n",
    "    Phi = polynomial_feature_map(X, k=i)\n",
    "    w = linear_regression(Phi, y_train)\n",
    "    error_vec.append(mse(y_train, polynomial(x, len(w), *w)))\n",
    "\n",
    "title(\"MSE vs k\")\n",
    "plot(range(1, 5), error_vec, '-o')\n",
    "xlabel('k')\n",
    "ylabel('Error')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_sigma(x, sigma):\n",
    "    epsilon = np.random.normal(scale=sigma, size=x.size)\n",
    "    return np.sin(2*np.pi*x)**2 + epsilon\n",
    "\n",
    "def exact(x):\n",
    "    return np.sin(2*np.pi*x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample_30 = np.random.random(size=30)\n",
    "x = np.arange(0, 1, 0.01)\n",
    "g_sigma_noise = partial(g_sigma, sigma=0.07)\n",
    "y_sample_30 = g_sigma_noise(x_sample_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title(\"Raw Data points and Exact Solution\")\n",
    "scatter(x_sample_30, y_sample_30)\n",
    "plot(x, exact(x))\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(x_sample_30)\n",
    "n = 1\n",
    "\n",
    "X_train = np.array(x_sample_30)\n",
    "X_train.shape = (m, n)\n",
    "y_train = y_sample_30\n",
    "y_train.shape = (1, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_vector = [2, 5, 10, 14, 18]\n",
    "\n",
    "for k in k_vector:\n",
    "    figure()\n",
    "    title(f'k={k}')\n",
    "    Phi = polynomial_feature_map(X_train, k)\n",
    "    w = linear_regression(Phi, y_train)\n",
    "    scatter(x_sample_30, polynomial(x_sample_30, len(w), *w), label=k)\n",
    "    scatter(x_sample_30, y_sample_30)\n",
    "ylim((-1.5, 1.5))\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(x_sample_30)\n",
    "n = 1\n",
    "\n",
    "X_train = np.array(x_sample_30)\n",
    "X_train.shape = (m, n)\n",
    "y_train = y_sample_30\n",
    "y_train.shape = (1, m)\n",
    "\n",
    "training_error_vec = []\n",
    "k_vector = [2, 5, 10, 14, 18]\n",
    "for k in k_vector:\n",
    "    Phi = polynomial_feature_map(X_train, k)\n",
    "    w = linear_regression(Phi, y_train)\n",
    "    error = mse(y_sample_30, polynomial(x_sample_30, len(w), *w))\n",
    "    training_error_vec.append(np.log(error))\n",
    "\n",
    "title(\"Training Error Vs $k$\")\n",
    "plot(k_vector, training_error_vec, '-o')\n",
    "xlabel('k')\n",
    "ylabel('ln(Error)')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The increasing error with K is due to the ill-conditioned matrix for large K values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample_1000 = np.random.random(size=1000)\n",
    "g_partial = partial(g_sigma, sigma=0.07)\n",
    "y_sample_1000 = g_partial(x_sample_1000)\n",
    "\n",
    "scatter(x_sample_1000, y_sample_1000)\n",
    "\n",
    "x = np.arange(0, 1, 0.01)\n",
    "y = np.sin(2*np.pi*x)**2\n",
    "\n",
    "plot(x, y, color='orange')\n",
    "title(\"Sample of 1000 points\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(x_sample_1000)\n",
    "n = 1\n",
    "\n",
    "X_test = np.array(x_sample_1000)\n",
    "X_test.shape = (m, n)\n",
    "y_test = y_sample_1000\n",
    "y_test.shape = (1, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_vec = []\n",
    "k_vector = arange(2,18,1)\n",
    "\n",
    "for k in k_vector:\n",
    "    Phi = polynomial_feature_map(X_train, k)\n",
    "    w = linear_regression(Phi, y_train)\n",
    "    error = mse(y_test, polynomial(x_sample_1000, len(w), *w))\n",
    "    test_error_vec.append(np.log(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title(\"Test Error Vs $k$\")\n",
    "plot(k_vector, test_error_vec, '-o')\n",
    "ylabel(\"ln(error)\")\n",
    "xlabel(\"$k$\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_vector = [2, 5, 10, 14, 18]\n",
    "\n",
    "for k in k_vector:\n",
    "    figure()\n",
    "    title(f'k={k}')\n",
    "    Phi = polynomial_feature_map(X_train, k)\n",
    "    w = linear_regression(Phi, y_train)\n",
    "\n",
    "    scatter(x_sample_1000, polynomial(x_sample_1000, len(w), *w), label=k)\n",
    "    scatter(x_sample_1000, y_sample_1000)\n",
    "\n",
    "    ylim((-1.5, 1.5))\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_experiment(feature_map, basis, x_sample, y_sample, k_vector):\n",
    "    m = len(x_sample)\n",
    "    n = 1\n",
    "\n",
    "    X = np.array(x_sample)\n",
    "    X.shape = (m, n)\n",
    "    y = y_sample\n",
    "    y.shape = (1, m)\n",
    "\n",
    "    error_vec = []\n",
    "    for k in k_vector:\n",
    "        Phi = feature_map(X, k)\n",
    "        w = linear_regression(Phi, y)\n",
    "        error = mse(y_sample, basis(x_sample, len(w), *w))\n",
    "        error_vec.append(error)\n",
    "    \n",
    "    return error_vec\n",
    "\n",
    "def runner(feature_map, basis, x_sample, k_vector, nruns=5):\n",
    "    \"\"\"\n",
    "    Function runner\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    for i in range(nruns):\n",
    "        y_sample = g_sigma_noise(x_sample)\n",
    "        results.append(error_experiment(feature_map, basis, x_sample, y_sample, k_vector))\n",
    "    return np.array(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = runner(polynomial_feature_map, polynomial, x_sample_30, [2, 5, 10, 14, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title(\"Train Error (100 Runs)\")\n",
    "plot(np.log(train_results.mean(axis=0)), '-o')\n",
    "xlabel('k')\n",
    "ylabel('Mean of ln(error)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = runner(polynomial_feature_map, polynomial, x_sample_1000, arange(2, 18, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title(\"Test Error (100 Runs)\")\n",
    "plot(np.log(test_results.mean(axis=0)), '-o')\n",
    "xlabel('k')\n",
    "ylabel('Mean of ln(error)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_feature_map(X, k=2):\n",
    "    \"\"\"\n",
    "    Number of features, n = 1.\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    \n",
    "    phi = np.zeros(shape=(m, k))\n",
    "    \n",
    "    for i, x in enumerate(X):\n",
    "        mapped_feature = np.zeros(shape=(k))\n",
    "        for j in range(k):\n",
    "            mapped_feature[j] = np.sin((j+1)*np.pi*x)\n",
    "        \n",
    "        phi[i] = mapped_feature\n",
    "    \n",
    "    return np.matrix(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal(x, k, *w):\n",
    "    \"\"\"\n",
    "    Apply sinusoidal weights derived from normal equations.\n",
    "    \"\"\"\n",
    "    result = np.zeros_like(x)\n",
    "    for i, sample in enumerate(x):\n",
    "        res = 0\n",
    "        for j in range(k):\n",
    "            res += w[j]*np.sin((j+1)*np.pi*sample)\n",
    "        result[i] = res\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_vector = arange(1, 18, 1)\n",
    "\n",
    "for k in k_vector:\n",
    "    figure()\n",
    "    title(f'k={k}')\n",
    "    Phi = sinusoidal_feature_map(X_train, k)\n",
    "    w = linear_regression(Phi, y_train)\n",
    "    scatter(x_sample_30, sinusoidal(x_sample_30, len(w), *w), label=k)\n",
    "    scatter(x_sample_30, y_sample_30)\n",
    "ylim((-1.5, 1.5))\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = runner(sinusoidal_feature_map, sinusoidal, x_sample_30, [2, 5, 10, 14, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title(\"Train Error (100 Runs)\")\n",
    "plot(np.log(train_results.mean(axis=0)), '-o')\n",
    "xlabel('k')\n",
    "ylabel('Mean of ln(error)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = runner(sinusoidal_feature_map, sinusoidal, x_sample_1000, arange(2, 18, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title(\"Test Error (100 Runs)\")\n",
    "plot(np.log(test_results.mean(axis=0)), '-o')\n",
    "xlabel('k')\n",
    "ylabel('Mean of ln(error)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.2 Boston housing and kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "boston_dataset = sio.loadmat('boston.mat')\n",
    "X, y = boston_dataset['boston'][:,:-1], boston_dataset['boston'][:, -1: ]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "m, n = X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a Fitting with a constant function\n",
    "\n",
    "Intuitively just finding the mean of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ones = np.ones_like(y_train)\n",
    "test_ones = np.ones_like(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = linear_regression(training_ones, y_train.T)\n",
    "plot(y_train, 'o', label='House Prices')\n",
    "plot(polynomial(X_train, len(w), *w), 'o')\n",
    "legend()\n",
    "ylabel('Price in $1000s')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train = mse(y_train, polynomial(X_train, len(w), *w))\n",
    "mse_test = mse(y_test, polynomial(X_test, len(w), *w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"MSE on the training data is {mse_train}\")\n",
    "print(f\"MSE on the test data is {mse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(X.T,X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\n",
    "\n",
    "This is like finding the mean of the dependent variable data, or just the bias term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_feature_map(X, k=None):\n",
    "    \"\"\"\n",
    "    Identity feature map, add a bias term.\n",
    "    \"\"\"\n",
    "   \n",
    "    m, n = X.shape\n",
    "    k = n + 1\n",
    "\n",
    "    phi = np.zeros(shape=(m, k))\n",
    "    \n",
    "    for i, x in enumerate(X):\n",
    "        mapped_feature = np.zeros(shape=(k))\n",
    "        for j in range(k-1):\n",
    "            mapped_feature[j] = x[j]\n",
    "        \n",
    "        # Add extra bias feature\n",
    "        mapped_feature[-1] = 1\n",
    "        \n",
    "        phi[i] = mapped_feature\n",
    "    \n",
    "    return np.matrix(phi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_predictor(x, w):\n",
    "    return np.dot(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pick out nth feature\n",
    "for n in range(1,13):\n",
    "\n",
    "    # Reshape, and use identity feature map to add bias term\n",
    "    feature_n = X_train[:,n].reshape(len(X_train), 1)\n",
    "    mapped_feature_n = identity_feature_map(feature_n)\n",
    "    w = linear_regression(mapped_feature_n, y_train.T)\n",
    "    mapped_feature_n_test = identity_feature_map(X_test[:,n].reshape(len(X_test), 1))\n",
    "    predictions = [float(identity_predictor(feat, w)) for feat in mapped_feature_n_test]\n",
    "    mean_square_error =  mse(y_train, predictions)\n",
    "    print(f\"MSE with feature {n} {mean_square_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_all_attributes = linear_regression(identity_feature_map(X_train), y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_all_attributes = [float(identity_predictor(feat, w_all_attributes)) for feat in identity_feature_map(X_test)]\n",
    "plot(y_test, 'o', label='House Prices')\n",
    "plot(predictions_all_attributes, 'o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_square_error =  mse(y_test, np.array(predictions_all_attributes))\n",
    "print(f\"MSE with feature all attributes {mean_square_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Kernelised Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(xi, xj, sigma=0.1):\n",
    "    tmp = np.linalg.norm(x=(xi-xj),ord=2)\n",
    "    return np.exp((-tmp**2)/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_regression(X_train, y_train, m, sigma, gamma):\n",
    "    K = np.zeros(shape=(m, m))\n",
    "\n",
    "    for i in range(0, m):\n",
    "        for j in range(0, m):\n",
    "            K[i][j] = gaussian_kernel(X_train[i], X_train[j], sigma)\n",
    "\n",
    "    K = np.matrix(K)\n",
    "    alpha_opt = np.matmul((K+(gamma*m*np.identity(m))).I, y_train)\n",
    "\n",
    "    return alpha_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_predictor(X_train, X_test, alpha_opt, sigma):\n",
    "    \n",
    "    m, n = X_train.shape\n",
    "    y_test = []\n",
    "\n",
    "    for i, x_test in enumerate(X_test):\n",
    "        res = 0\n",
    "        for j in range(m):\n",
    "            res += float(alpha_opt[j]*gaussian_kernel(x_test, X_train[j], sigma))\n",
    "        y_test.append(res)\n",
    "\n",
    "    return np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "boston_dataset = sio.loadmat('boston.mat')\n",
    "X, y = boston_dataset['boston'][:,:-1], boston_dataset['boston'][:, -1: ]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "m, n = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_vector = np.array(\n",
    "    [2**(i) for i in range(-40, -25, 1)]\n",
    ")\n",
    "\n",
    "sigma_vector = np.array(\n",
    "    [2**(i) for i in linspace(7,13,13)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Learn parameters\n",
    "sigma = sigma_vector[0]\n",
    "gamma = gamma_vector[2]\n",
    "\n",
    "alpha_opt = kernel_regression(X_train, y_train, m, sigma, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = kernel_predictor(X_train, X_test, alpha_opt, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    (sigma, gamma) \n",
    "    for sigma in sigma_vector\n",
    "    for gamma in gamma_vector\n",
    "]\n",
    "shuffle(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 195 parameter combinations\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(parameters)} parameter combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_validation(X, y, sigma, gamma, k=5):\n",
    "    \n",
    "    kf = KFold(n_splits=k)\n",
    "    errors = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        m, n = X_train.shape\n",
    "\n",
    "        alpha_opt = kernel_regression(\n",
    "            X_train, y_train, m, sigma, gamma)\n",
    "        \n",
    "\n",
    "        y_hat = kernel_predictor(\n",
    "            X_train, X_test, alpha_opt, sigma)\n",
    "\n",
    "        error = sse(y_test, y_hat)\n",
    "        errors.append(error)\n",
    "    \n",
    "    return np.array(errors).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run cross validation experiments over all parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_results = []\n",
    "\n",
    "for (s, g) in parameters[:9]:\n",
    "    cross_validation_results.append(\n",
    "        (s, g, kfold_cross_validation(X, y, s, g))\n",
    "    )\n",
    "\n",
    "    \n",
    "# Convert to array for ease of indexing\n",
    "cross_validation_results  = np.array(cross_validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.24077344e+02, 7.45058060e-09, 2.01633870e+06],\n",
       "       [5.79261875e+03, 1.86264515e-09, 1.17673954e+06],\n",
       "       [7.24077344e+02, 3.72529030e-09, 2.28072059e+06],\n",
       "       [4.09600000e+03, 9.31322575e-10, 1.24259167e+06],\n",
       "       [1.28000000e+02, 2.91038305e-11, 8.29778411e+08],\n",
       "       [8.19200000e+03, 3.72529030e-09, 1.10162399e+06],\n",
       "       [4.09600000e+03, 2.32830644e-10, 1.24187972e+06],\n",
       "       [1.81019336e+02, 7.27595761e-12, 9.25741773e+08],\n",
       "       [1.28000000e+02, 3.63797881e-12, 3.45613041e+09]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas, sigmas, cv_error = (\n",
    "    cross_validation_results[:,0:1],\n",
    "    cross_validation_results[:,1:2],\n",
    "    cross_validation_results[:,2:]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
